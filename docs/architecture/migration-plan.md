# План миграции и отката

Документ описывает последовательный переход от существующего монолита Zemo на модульную архитектуру.

## Фазы миграции

### Фаза 0 — Подготовка
- Утвердить ADR и архитектурные артефакты.
- Создать репозиторий и структуру каталогов (текущий шаг).
- Настроить общие практики (CI, линтеры, форматтеры, pre-commit).

### Фаза 1 — Инфраструктурный фундамент
1. Развернуть обновлённый `docker-compose` (PostgreSQL, Redis, phpmorphy) на staging.
2. Настроить бэкапы PostgreSQL + мониторинг (Prometheus/Grafana).
3. Включить `pgcrypto`, `pgvector`, `uuid-ossp`.
4. Подготовить шаблон `.env` и секреты (Docker secrets/Vault).

### Фаза 2 — Данные и миграции
1. Сконвертировать существующие SQLite схемы в Prisma schema.
2. Сгенерировать и применить initial миграции в новой БД.
3. Реализовать ETL-пайплайн для переноса исторических данных (SQLite → PostgreSQL) — отдельный временный worker.
4. Ввести режим двойной записи в монолите и валидировать целостность данных.

### Фаза 3 — API сервис
1. Реализовать NestJS API (`apps/api`):
   - identity, settings, prompts, jobs, analytics модули.
   - SSR-шаблоны (минимальные страницы dashboard, список задач, просмотр логов).
   - Swagger/OpenAPI генерация.
   - Логирование Pino + requestId.
2. Подключить Redis для постановки задач, организовать rate limiting.
3. Настроить Socket.IO/SSE гейтвей для стрима логов задач.
4. Ввести feature flag, позволяющий переключать клиентов с монолита на новый API.

### Фаза 4 — Worker сервис
1. Реализовать BullMQ воркеры (`apps/worker`): consumer'ы для `serp`, `scrape`, `analyze`, `generate`, `pipeline`.
2. Настроить Puppeteer pool, ограничение конкурентности и backoff.
3. Инкапсулировать интеграции SerpApi и LLM в адаптеры (с retry, rate limit).
4. Подключить pgcrypto для расшифровки API ключей, логирование прогресса задач.

### Фаза 5 — Переезд трафика
1. На staging провести end-to-end тесты, замерить latency, проверить SLO.
2. В production включить режим shadow-трафика (дублирование запросов) для API и воркеров.
3. После успешного мониторинга переключить основной трафик на новые сервисы.
4. В течение 1–2 недель держать монолит в режиме read-only, собирая метрики и логи.
5. Отключить монолит, обновить документацию и runbooks.

## Риски и меры
| Риск | Влияние | Митигирующие действия |
|------|---------|-----------------------|
| Несовпадение схем данных | Потеря данных | Автоматические тесты миграций, checksum сверки, ручная валидация ключевых таблиц. |
| Ограничения внешних API | Задержки в задачах | Встроенный backoff, кеширование, fallback очереди. |
| Нагрузка Puppeteer | Падение воркеров | Ограничение сессий, автоматический рестарт, мониторинг ресурсов. |
| Секреты в открытом доступе | Компрометация данных | Использование Docker secrets/Vault, ревизия прав доступа. |
| Наблюдаемость | Трудности расследования инцидентов | Стандартизованные логи, обязательные traceId/jobId, заранее подготовленные дашборды. |

## План отката
1. **API сервис**
   - Переключить ingress/DNS обратно на монолит.
   - Отключить постановку задач в новых очередях (pause BullMQ).
   - Сохранить snapshot Redis для восстановления.

2. **Worker сервис**
   - Завершить текущие задачи, выгрузить логи.
   - Активировать старые фоновые процессы в монолите (если оставлены).

3. **База данных**
   - Восстановить последнюю стабильную резервную копию PostgreSQL.
   - При необходимости вернуться на SQLite (только после ручной оценки потерь).

4. **Коммуникация**
   - Уведомить заинтересованные стороны, зафиксировать инцидент и шаги отката в runbook.

## Контрольные точки
- ✔️ Утверждённые ADR и архитектурные документы.
- ✔️ Применён initial миграционный пакет в PostgreSQL.
- ✔️ Внедрён API с покрытием OpenAPI.
- ✔️ Настроены очереди и worker-процессы с мониторингом.
- ✔️ Подтверждена доступность (>=99.5%) на этапе shadow-трафика.

План подлежит актуализации по результатам разработки и пилотных запусков.
